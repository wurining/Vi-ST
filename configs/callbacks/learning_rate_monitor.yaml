# https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.callbacks.LearningRateMonitor.html

vae_prediction_writer:
  _target_: lightning.pytorch.callbacks.LearningRateMonitor
  logging_interval: epoch #(Optional[str]) – set to 'epoch' or 'step' to log lr of all optimizers at the same interval, set to None to log at individual interval according to the interval key of each scheduler. Defaults to None.
  log_momentum: false # (bool) – option to also log the momentum values of the optimizer, if the optimizer has the momentum or betas attribute. Defaults to False.
